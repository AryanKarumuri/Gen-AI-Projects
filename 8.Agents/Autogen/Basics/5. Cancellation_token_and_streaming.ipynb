{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad321f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "model_client = OpenAIChatCompletionClient(model='gemini-2.5-flash', api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4b8c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def name_tool(query: str)->str:\n",
    "    return \"Superman returns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3899f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AssistantAgent(\n",
    "    name='assistant',\n",
    "    model_client=model_client,\n",
    "    tools=[name_tool],\n",
    "    system_message='Use Tool to get names'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7f56c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Superman returns\n"
     ]
    }
   ],
   "source": [
    "result = await agent.run(task='Find information about Superman')\n",
    "print(result.messages[-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584b21e2",
   "metadata": {},
   "source": [
    "#### `on_message()` Method\n",
    "\n",
    "- In AutoGen, agents communicate by sending and receiving messages. The on_message() method is a callback used to define how an agent reacts to a message.\n",
    "- It intercepts an incoming message and optionally returns a response.\n",
    "- You can override on_message() to customize the agent's behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94446d87",
   "metadata": {},
   "source": [
    "#### Cancellation Token\n",
    "\n",
    "AutoGen agents often run in conversational loops that can continue indefinitely. A cancellation token is a control mechanism to stop or cancel such ongoing interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30a5de8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolCallRequestEvent(id='b32dbd5e-04c8-45ec-b4d1-7cfd9ad4be97', source='assistant', models_usage=RequestUsage(prompt_tokens=139, completion_tokens=15), metadata={}, created_at=datetime.datetime(2025, 7, 21, 18, 19, 18, 968811, tzinfo=datetime.timezone.utc), content=[FunctionCall(id='', arguments='{\"query\":\"Superman\"}', name='name_tool')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(id='e79af94f-32a4-4c10-843d-56a3b83d140f', source='assistant', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 21, 18, 19, 18, 972037, tzinfo=datetime.timezone.utc), content=[FunctionExecutionResult(content='Superman returns', name='name_tool', call_id='', is_error=False)], type='ToolCallExecutionEvent')]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Superman returns\n"
     ]
    }
   ],
   "source": [
    "from autogen_core import CancellationToken\n",
    "\n",
    "async def assistant_run()-> None:\n",
    "    response = await agent.on_messages(\n",
    "        messages= [TextMessage(content='Find information about Superman',source='User')],\n",
    "        cancellation_token=CancellationToken()\n",
    "    )\n",
    "\n",
    "    print(response.inner_messages)\n",
    "    print('\\n\\n\\n\\n')\n",
    "    print(response.chat_message.content)\n",
    "\n",
    "await assistant_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29409e58",
   "metadata": {},
   "source": [
    "#### Streaming Messages\n",
    "\n",
    "`on_messages_stream()`: method in AutoGen is an advanced hook used to handle streamed message events in a multi-agent chat session. It complements on_message() by allowing an agent to react to messages incrementally as they arrive, instead of waiting for the entire message to be delivered.\n",
    "\n",
    "| Method                 | When Called                                                                    |\n",
    "| ---------------------- | ------------------------------------------------------------------------------ |\n",
    "| `on_message()`         | Called **after** the full message is received.                                 |\n",
    "| `on_messages_stream()` | Called **as the message is being streamed**, token by token or chunk by chunk. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9240a84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- ToolCallRequestEvent (assistant) ----------\n",
      "[FunctionCall(id='', arguments='{\"query\":\"Superman\"}', name='name_tool')]\n",
      "[Prompt tokens: 179, Completion tokens: 15]\n",
      "---------- ToolCallExecutionEvent (assistant) ----------\n",
      "[FunctionExecutionResult(content='Superman returns', name='name_tool', call_id='', is_error=False)]\n",
      "---------- assistant ----------\n",
      "Superman returns\n",
      "---------- Summary ----------\n",
      "Number of inner messages: 2\n",
      "Total prompt tokens: 179\n",
      "Total completion tokens: 15\n",
      "Duration: 2.38 seconds\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "\n",
    "async def assistant_run_stream() -> None:\n",
    "\n",
    "    await Console(\n",
    "        agent.on_messages_stream(\n",
    "        messages= [TextMessage(content='Find information about Superman via the tool',source='User')],\n",
    "        cancellation_token=CancellationToken()\n",
    "    ),\n",
    "    output_stats=True # Enable stats Printing\n",
    "    )\n",
    "\n",
    "\n",
    "await assistant_run_stream()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vir_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
