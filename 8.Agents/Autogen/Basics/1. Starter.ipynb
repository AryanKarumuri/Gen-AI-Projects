{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b08efc",
   "metadata": {},
   "source": [
    "### Simple Autogen Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d62ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e4f935",
   "metadata": {},
   "source": [
    "#### List All Available Gemini Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c3d358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\srirajax\\OneDrive - Intel Corporation\\Documents\\Aryan\\Python cheat codes\\Agents\\vir_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-05-20\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-flash-lite-preview-06-17\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "models/veo-2.0-generate-001\n",
      "models/veo-3.0-generate-preview\n",
      "models/gemini-2.5-flash-preview-native-audio-dialog\n",
      "models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
      "models/gemini-2.0-flash-live-001\n",
      "models/gemini-live-2.5-flash-preview\n",
      "models/gemini-2.5-flash-live-preview\n"
     ]
    }
   ],
   "source": [
    "# Install the Google Generative AI SDK to access and list all available Gemini models\n",
    "# You can install it using the following command:\n",
    "# pip install google-generativeai\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# List all models\n",
    "models = genai.list_models()\n",
    "\n",
    "for model in models:\n",
    "    print(model.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f02d9",
   "metadata": {},
   "source": [
    "#### Connecting to the model\n",
    "We use `OpenAIChatCompletionClient` to link our agent to Gemini('gemini-2.5-flash'). In v0.4, this replaces the older `llm_config` approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9419f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key set up successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model_client = OpenAIChatCompletionClient(model='gemini-2.5-flash',api_key=api_key)\n",
    "    print(\"API key set up successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError created due to: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f9a170",
   "metadata": {},
   "source": [
    "#### Building the Agent\n",
    "The `AssistantAgent` is a conversational AI that can respond to tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0543f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = AssistantAgent(name='personal_assistant', model_client=model_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373a4919",
   "metadata": {},
   "source": [
    "#### Querying our Agent\n",
    "We’ll use the `run` method—a simple way in v0.4 to get a response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2822b59",
   "metadata": {},
   "source": [
    "#### Query-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95946b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await assistant.run(task=\"What is Agentic AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db65d55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[TextMessage(id='15321f5b-db1a-426b-a6e2-48e0b7ccd7d3', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 20, 18, 40, 26, 781123, tzinfo=datetime.timezone.utc), content='What is Agentic AI?', type='TextMessage'), TextMessage(id='69ccea21-5afd-4bfe-a251-385b764ff707', source='personal_assistant', models_usage=RequestUsage(prompt_tokens=94, completion_tokens=190), metadata={}, created_at=datetime.datetime(2025, 7, 20, 18, 40, 29, 968046, tzinfo=datetime.timezone.utc), content='Agentic AI refers to AI systems designed to act as intelligent agents. This means they are capable of:\\n\\n*   **Perception:** Taking in information from their environment (data, user input, sensor readings, etc.).\\n*   **Reasoning:** Processing that information, making decisions, and planning actions.\\n*   **Action:** Executing those plans within their environment to achieve a specific goal.\\n*   **Autonomy:** Operating independently for extended periods without constant human intervention, within defined parameters.\\n*   **Goal-Oriented Behavior:** Working towards a predefined objective or set of objectives.\\n\\nEssentially, an agentic AI is not just a passive tool that responds to prompts, but a system that can understand a goal, formulate a strategy, execute it, and adapt based on feedback from its environment, much like a human agent would. This often involves chaining together multiple AI models and tools to achieve complex tasks.TERMINATE', type='TextMessage')] stop_reason=None\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "564714a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant response:\n",
      " Agentic AI refers to AI systems designed to act as intelligent agents. This means they are capable of:\n",
      "\n",
      "*   **Perception:** Taking in information from their environment (data, user input, sensor readings, etc.).\n",
      "*   **Reasoning:** Processing that information, making decisions, and planning actions.\n",
      "*   **Action:** Executing those plans within their environment to achieve a specific goal.\n",
      "*   **Autonomy:** Operating independently for extended periods without constant human intervention, within defined parameters.\n",
      "*   **Goal-Oriented Behavior:** Working towards a predefined objective or set of objectives.\n",
      "\n",
      "Essentially, an agentic AI is not just a passive tool that responds to prompts, but a system that can understand a goal, formulate a strategy, execute it, and adapt based on feedback from its environment, much like a human agent would. This often involves chaining together multiple AI models and tools to achieve complex tasks.TERMINATE\n"
     ]
    }
   ],
   "source": [
    "print(\"Assistant response:\\n\",result.messages[-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8e9526",
   "metadata": {},
   "source": [
    "#### Query-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66acbc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is **3**.\n",
      "\n",
      "Here's how:\n",
      "1.  11 multiplied by 3 equals 33.\n",
      "2.  33 divided by 11 equals 3.\n",
      "\n",
      "Alternatively, since you're multiplying by 11 and then dividing by 11, the 11s cancel each other out, leaving just 3.\n"
     ]
    }
   ],
   "source": [
    "result = await assistant.run(task=\"what is the answer of 11*3/11?\")\n",
    "print(result.messages[-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vir_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
