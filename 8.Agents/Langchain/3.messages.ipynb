{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "606d1663",
   "metadata": {},
   "source": [
    "### Messages\n",
    "\n",
    "Messages define the conversational context in LangChain. They model the inputs and outputs exchanged with an LLM and include both content and metadata necessary for state management.\n",
    "\n",
    "Each message object contains:\n",
    "\n",
    "- A role indicating its function in the conversation (e.g., system, user)\n",
    "- Content representing the message payload in one or more modalities\n",
    "- Optional metadata, such as response information, message identifiers, and token counts\n",
    "\n",
    "LangChain abstracts these messages into a provider-agnostic format, enabling consistent interaction across all supported models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c98506e",
   "metadata": {},
   "source": [
    "### Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8ef38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "OLLAMA_URL = \"\" # Specify your Ollama server URL here\n",
    "OLLAMA_MODEL = \"granite4:tiny-h\"\n",
    "\n",
    "model = ChatOllama(model=OLLAMA_MODEL, base_url=OLLAMA_URL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd2ed8",
   "metadata": {},
   "source": [
    "### Simple Text Prompt\n",
    "\n",
    "- Suitable/Ideal for simple text generation tasks.\n",
    "\n",
    "**Usage:**\n",
    "This approach is best suited for scenarios where:\n",
    "\n",
    " - There is a single, standalone request\n",
    " - Conversation history is not required\n",
    " - Minimal code complexity is desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce809d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! It's nice to meet you. How can I assist you today? Feel free to ask me anything or let me know if there are any specific tasks you'd like help with. I'm here to provide information, answer your questions, and engage in conversation as much as I'm able.\", additional_kwargs={}, response_metadata={'model': 'granite4:tiny-h', 'created_at': '2026-01-03T09:48:18.4994779Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1005453500, 'load_duration': 40992600, 'prompt_eval_count': 12, 'prompt_eval_duration': 155449400, 'eval_count': 61, 'eval_duration': 783728900, 'logprobs': None, 'model_name': 'granite4:tiny-h', 'model_provider': 'ollama'}, id='lc_run--019b8341-f47d-7131-9cea-e173f109ea6b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 12, 'output_tokens': 61, 'total_tokens': 73})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f82d5af",
   "metadata": {},
   "source": [
    "## Message Prompt\n",
    "\n",
    "Message prompts play a critical role in guiding how a model understands context, processes input, and generates responses. They define the structure of communication between the user, the system, the AI model, and external tools.\n",
    "\n",
    "**Types:**\n",
    "- System message - Tells the model how to behave and provide context for interactions\n",
    "- Human message - Represents user input and interactions with the model\n",
    "- AI message - Responses generated by the model, including text content, tool calls, and metadata\n",
    "- Tool message - Represents the outputs of tool calls\n",
    "\n",
    "## Types of Message Prompts\n",
    "\n",
    "### 1. System Message\n",
    "\n",
    "A **System Message** represents an initial set of instructions that primes the model’s behavior for the entire conversation.\n",
    "\n",
    "#### Purpose\n",
    "- Establishes the model’s role (e.g., assistant, tutor, analyst)\n",
    "- Defines behavioral rules and constraints\n",
    "- Sets tone, style, and response guidelines\n",
    "- Provides persistent context across interactions\n",
    "\n",
    "#### Key Characteristics\n",
    "- Typically sent once at the beginning of a conversation\n",
    "- Has the highest priority when resolving instruction conflicts\n",
    "- Not directly visible to end users\n",
    "- Influences all subsequent AI responses\n",
    "\n",
    "#### Example Use Cases\n",
    "- Enforcing concise or professional language\n",
    "- Limiting responses to a specific domain\n",
    "- Preventing disallowed behaviors\n",
    "- Defining expertise (e.g., “You are a legal research assistant”)\n",
    "\n",
    "\n",
    "### 2. Human Message\n",
    "\n",
    "A **Human Message** represents user input and interaction with the model.\n",
    "\n",
    "#### Purpose\n",
    "- Captures user intent, questions, or commands\n",
    "- Drives the conversational flow\n",
    "- Requests explanations, actions, or creative output\n",
    "\n",
    "#### Supported Content Types\n",
    "- Text\n",
    "- Images\n",
    "- Audio\n",
    "- Files or documents\n",
    "- Multimodal input (e.g., text combined with images)\n",
    "\n",
    "#### Key Characteristics\n",
    "- Can occur multiple times in a conversation\n",
    "- Interpreted in the context of prior system and AI messages\n",
    "- Lower priority than system messages but higher than AI-generated content\n",
    "\n",
    "\n",
    "### 3. AI Message\n",
    "\n",
    "An **AI Message** represents the output generated by the model in response to system and human messages.\n",
    "\n",
    "#### Purpose\n",
    "- Provides answers, explanations, or generated content\n",
    "- Performs reasoning or summarization\n",
    "- Initiates tool calls when additional data or computation is required\n",
    "\n",
    "#### Possible Contents\n",
    "- Natural language text\n",
    "- Structured formats (e.g., JSON)\n",
    "- Multimodal outputs (where supported)\n",
    "- Tool call instructions\n",
    "- Provider-specific metadata (e.g., token usage, confidence scores)\n",
    "\n",
    "#### Key Characteristics\n",
    "- Generated dynamically by the model\n",
    "- Adheres to constraints defined by the system message\n",
    "- May require follow-up tool execution\n",
    "\n",
    "\n",
    "### 4. Tool Message\n",
    "\n",
    "A **Tool Message** represents the output of a tool or function execution.\n",
    "\n",
    "#### Purpose\n",
    "- Returns results from external tools back to the model\n",
    "- Enables the model to reason using real-time or computed data\n",
    "- Supports advanced workflows and automation\n",
    "\n",
    "#### Key Characteristics\n",
    "- Always linked to a specific tool call made by an AI message\n",
    "- Contains structured output from a single tool execution\n",
    "- Not authored by the model, but consumed by it\n",
    "\n",
    "#### Common Use Cases\n",
    "- Database or knowledge-base queries\n",
    "- Web search results\n",
    "- Code execution outputs\n",
    "- File processing\n",
    "- Mathematical or analytical computations\n",
    "\n",
    "\n",
    "## Message Priority Hierarchy\n",
    "\n",
    "| Message Type   | Role                          | Source               | Priority |\n",
    "|---------------|-------------------------------|----------------------|----------|\n",
    "| System Message | Defines behavior and rules    | Application / System | Highest  |\n",
    "| Human Message  | Provides user input           | End User             | High     |\n",
    "| AI Message     | Generates responses           | Model                | Medium   |\n",
    "| Tool Message   | Returns tool execution output | External Tool        | Contextual |\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "These four message types together form a **structured and extensible communication framework** for AI-driven systems. Proper sequencing and usage of system, human, AI, and tool messages significantly improve:\n",
    "\n",
    "- Response accuracy\n",
    "- Context retention\n",
    "- Behavioral control\n",
    "- Integration with external systems\n",
    "\n",
    "This architecture is foundational for building reliable, scalable, and intelligent conversational applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b0d4ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Sea's Eternal Embrace\\n\\nUpon the vast, celestial canvas,\\nA liquid masterpiece unfolds.\\nIn azure hues and sapphire splendor,\\nThe ocean's beauty forever holds.\\n\\nEndless waves caress the shore,\\nTheir rhythmic dance a timeless song.\\nEach crest and trough, a story told,\\nOf journeys long and destinies strong.\\n\\nBeneath its surface lies a realm\\nWhere secrets dwell in silence deep.\\nCreatures of wonder never seen,\\nIn coral kingdoms they do sleep.\\n\\nFrom distant shores to hidden coves,\\nThe sea's embrace knows no bounds.\\nA force both gentle and profound,\\nIts mysteries forever surround.\\n\\nOh mighty ocean, ever true,\\nYour depths hold worlds we long to know.\\nWith every sunrise and setting sun,\\nWe stand in awe of your majesty's glow.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage,AIMessage\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(\"You are a poetry expert\"),\n",
    "    HumanMessage(\"Write a poem on the sea\"),\n",
    "]\n",
    "\n",
    "response=model.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "154d9be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a FastAPI application, follow these steps:\n",
      "\n",
      "1. Install FastAPI and Uvicorn:\n",
      "   ```\n",
      "   pip install fastapi uvicorn\n",
      "   ```\n",
      "\n",
      "2. Create a new Python file, e.g., `main.py`, and import the necessary modules:\n",
      "   ```python\n",
      "   from fastapi import FastAPI\n",
      "\n",
      "   app = FastAPI()\n",
      "   ```\n",
      "\n",
      "3. Define your API routes using FastAPI's built-in decorators:\n",
      "   ```python\n",
      "   @app.get(\"/\")\n",
      "   def home():\n",
      "       return {\"message\": \"Hello, World!\"}\n",
      "\n",
      "   @app.get(\"/items/{item_id}\")\n",
      "   def read_item(item_id: int, q: str = None):\n",
      "       return {\"item_id\": item_id, \"q\": q}\n",
      "   ```\n",
      "\n",
      "4. Run the FastAPI application using Uvicorn:\n",
      "   ```python\n",
      "   if __name__ == \"__main__\":\n",
      "       import uvicorn\n",
      "\n",
      "       uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
      "   ```\n",
      "\n",
      "5. Save the file and run it using the following command in your terminal:\n",
      "   ```\n",
      "   uvicorn main:app --reload\n",
      "   ```\n",
      "\n",
      "   This will start the FastAPI server, and you can access your API at `http://localhost:8000`.\n",
      "\n",
      "Here's a complete example of a basic FastAPI application:\n",
      "\n",
      "```python\n",
      "from fastapi import FastAPI\n",
      "\n",
      "app = FastAPI()\n",
      "\n",
      "@app.get(\"/\")\n",
      "def home():\n",
      "    return {\"message\": \"Hello, World!\"}\n",
      "\n",
      "@app.get(\"/items/{item_id}\")\n",
      "def read_item(item_id: int, q: str = None):\n",
      "    return {\"item_id\": item_id, \"q\": q}\n",
      "```\n",
      "\n",
      "You can add more routes and define additional functionality as needed. FastAPI provides a lot of features like request parsing, dependency injection, automatic documentation (via Swagger UI), and more.\n",
      "\n",
      "Remember to install the necessary dependencies (`fastapi` and `uvicorn`) before running your FastAPI application.\n",
      "\n",
      "FastAPI is known for its simplicity, performance, and ease of use, making it a popular choice for building APIs in Python.\n"
     ]
    }
   ],
   "source": [
    "system_msg = SystemMessage(\"You are a helpful coding assistant.\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"How do I create a FAST API?\")\n",
    "]\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02703755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a REST API involves several key steps, regardless of the framework you choose. Below is a basic example using **Flask**, a lightweight Python web framework, to demonstrate how to set up a simple REST API. \n",
      "\n",
      "### Step 1: Set Up Your Environment\n",
      "\n",
      "First, ensure you have Python installed on your system. It's recommended to use a virtual environment:\n",
      "\n",
      "```bash\n",
      "python3 -m venv venv\n",
      "source venv/bin/activate\n",
      "pip install Flask\n",
      "```\n",
      "\n",
      "### Step 2: Install Flask\n",
      "\n",
      "Flask is used here because of its simplicity and ease of use for beginners, but the concepts apply similarly to other frameworks like Django (with Django REST Framework), FastAPI, or Express.js if you're using Node.js.\n",
      "\n",
      "### Step 3: Create Your API Application\n",
      "\n",
      "Create a file named `app.py`:\n",
      "\n",
      "```python\n",
      "from flask import Flask, jsonify, request\n",
      "\n",
      "app = Flask(__name__)\n",
      "\n",
      "# Sample data - In a real application, this would likely come from a database\n",
      "books = [\n",
      "    {\"id\": 1, \"title\": \"Flask Web Development\", \"author\": \"Miguel Grinberg\"},\n",
      "    {\"id\": 2, \"title\": \"Learning Python\", \"author\": \"Mark Lutz\"}\n",
      "]\n",
      "\n",
      "# GET /books - Retrieve all books\n",
      "@app.route('/books', methods=['GET'])\n",
      "def get_books():\n",
      "    return jsonify(books)\n",
      "\n",
      "# POST /books - Create a new book\n",
      "@app.route('/books', methods=['POST'])\n",
      "def add_book():\n",
      "    new_book = request.get_json()\n",
      "    new_book['id'] = len(books) + 1  # Simple ID assignment for demonstration\n",
      "    books.append(new_book)\n",
      "    return jsonify(new_book), 201\n",
      "\n",
      "# GET /books/<int:book_id> - Retrieve a specific book by ID\n",
      "@app.route('/books/<int:book_id>', methods=['GET'])\n",
      "def get_book(book_id):\n",
      "    book = next((b for b in books if b['id'] == book_id), None)\n",
      "    if not book:\n",
      "        return jsonify({\"error\": \"Book not found\"}), 404\n",
      "    return jsonify(book)\n",
      "\n",
      "# PUT /books/<int:book_id> - Update a specific book by ID\n",
      "@app.route('/books/<int:book_id>', methods=['PUT'])\n",
      "def update_book(book_id):\n",
      "    updated_book = request.get_json()\n",
      "    book = next((b for b in books if b['id'] == book_id), None)\n",
      "    if not book:\n",
      "        return jsonify({\"error\": \"Book not found\"}), 404\n",
      "    book.update(updated_book)\n",
      "    return jsonify(book)\n",
      "\n",
      "# DELETE /books/<int:book_id> - Delete a specific book by ID\n",
      "@app.route('/books/<int:book_id>', methods=['DELETE'])\n",
      "def delete_book(book_id):\n",
      "    global books\n",
      "    books = [b for b in books if b['id'] != book_id]\n",
      "    return '', 204\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    app.run(debug=True)\n",
      "```\n",
      "\n",
      "### Explanation of the Code\n",
      "\n",
      "1. **Flask Setup**: We import Flask and create an instance of the `Flask` application.\n",
      "2. **Sample Data**: For simplicity, we use a list to simulate database data.\n",
      "3. **Routes**:\n",
      "   - **GET /books**: Retrieves all books.\n",
      "   - **POST /books**: Adds a new book. Note that we parse JSON from the request body using `request.get_json()`.\n",
      "   - **GET /books/<int:book_id>**: Retrieves a specific book by ID.\n",
      "   - **PUT /books/<int:book_id>**: Updates a specific book by ID.\n",
      "   - **DELETE /books/<int:book_id>**: Deletes a specific book by ID.\n",
      "\n",
      "4. **Error Handling**:\n",
      "   - We return appropriate HTTP status codes (`404` for not found, `201` on successful creation).\n",
      "   - For POST and PUT requests, we expect JSON data to be sent in the request body.\n",
      "\n",
      "### Step 4: Run Your Application\n",
      "\n",
      "Run your Flask application by executing:\n",
      "\n",
      "```bash\n",
      "python app.py\n",
      "```\n",
      "\n",
      "By default, Flask will run on `http://127.0.0.1:5000/`. You can test your API using tools like **Postman** or **curl**.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "This is a basic example to get you started with creating a REST API in Python using Flask. In production environments, consider using more robust frameworks (like Django REST Framework), implementing authentication mechanisms, and handling data persistence with databases instead of in-memory structures.\n"
     ]
    }
   ],
   "source": [
    "## Detailed info to the LLM through System message\n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "system_msg = SystemMessage(\"\"\"\n",
    "You are a senior Python developer with expertise in web frameworks.\n",
    "Always provide code examples and explain your reasoning.\n",
    "Be concise but thorough in your explanations.\n",
    "\"\"\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"How do I create a REST API?\")\n",
    "]\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2690963",
   "metadata": {},
   "source": [
    "### Message Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a477f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_msg = HumanMessage(\n",
    "    content=\"Hello!\",\n",
    "    name=\"Superman\",  \n",
    "    id=\"id_123\",  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5fd5075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='*The door swings open and I step inside, looking around at the cozy living room. A young woman sits on the couch, fiddling with her phone. She looks up as you enter.*\\n\\nOh, hey there! Welcome back. How can I help you today?\\n\\n*I gesture to a chair near the window.* Please have a seat. Is there something specific you needed assistance with?', additional_kwargs={}, response_metadata={'model': 'granite4:tiny-h', 'created_at': '2026-01-03T11:39:02.8439318Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1151079400, 'load_duration': 35880100, 'prompt_eval_count': 10, 'prompt_eval_duration': 149628800, 'eval_count': 79, 'eval_duration': 939093400, 'logprobs': None, 'model_name': 'granite4:tiny-h', 'model_provider': 'ollama'}, id='lc_run--019b83a7-55ea-7893-9bc1-2fd4e6428722-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 10, 'output_tokens': 79, 'total_tokens': 89})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke([\n",
    "  human_msg\n",
    "])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c95f617b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of 2+2 is 4.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import AIMessage, SystemMessage, HumanMessage\n",
    "\n",
    "# Create an AI message manually (e.g., for conversation history)\n",
    "ai_msg = AIMessage(\"I'd be happy to help you with that question!\")\n",
    "\n",
    "# Add to conversation history\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant\"),\n",
    "    HumanMessage(\"Can you help me?\"),\n",
    "    ai_msg,\n",
    "    HumanMessage(\"Great! What's 2+2?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
