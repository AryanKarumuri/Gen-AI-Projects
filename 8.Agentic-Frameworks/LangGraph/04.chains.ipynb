{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4cd779d",
   "metadata": {},
   "source": [
    "## Chains in Langgraph\n",
    "\n",
    "**Topics:**\n",
    "- `chat messages` as graph state\n",
    "- `chat models` in graph nodes\n",
    "- `bind tools` to LLMs\n",
    "- `executing the tools` in graph nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85376d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OLLAMA_BASE_URL = os.getenv(\"OLLAMA_BASE_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e214c",
   "metadata": {},
   "source": [
    "## Chat Messages\n",
    "\n",
    "Message prompts play a critical role in guiding how a model understands context, processes input, and generates responses. They define the structure of communication between the user, the system, the AI model, and external tools.\n",
    "\n",
    "**Types:**\n",
    "\n",
    "- System message - Tells the model how to behave and provide context for interactions\n",
    "- Human message - Represents user input and interactions with the model\n",
    "- AI message - Responses generated by the model, including text content, tool calls, and metadata\n",
    "- Tool message - Represents the outputs of tool calls\n",
    "\n",
    "Every message have these important components.\n",
    "\n",
    "- content - content of the message\n",
    "- name - Specify the name of author\n",
    "- response_metadata - optionally, a dict of metadata (e.g., often populated by model provider for AIMessages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d096b9",
   "metadata": {},
   "source": [
    "| Message Type | Role | Source | Priority |\n",
    "|--------------|------|--------|----------|\n",
    "| **System Message** | Defines behavior and rules | Application / System | Highest |\n",
    "| **Human Message** | Provides user input | End User | High |\n",
    "| **AI Message** | Generates responses | Model | Medium |\n",
    "| **Tool Message** | Returns tool execution output | External Tool | Contextual |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97339159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for message types\n",
    "\n",
    "from langchain_core.messages import BaseMessage, AIMessage, HumanMessage, SystemMessage\n",
    "from pprint import pprint\n",
    "\n",
    "messages = [AIMessage(content=\"Hello! I'm here to help you.\", name=\"assistant\")]\n",
    "messages.append(HumanMessage(content=\"What can you do?\", name=\"user\"))\n",
    "\n",
    "for message in messages:\n",
    "    message.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df506e8",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "\n",
    "Chat models in LangChain accept a **sequence of messages** as input and generate AI responses.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "- Accept multiple message types (System, Human, AI, Tool)\n",
    "- Maintain conversation context through message history\n",
    "- Support streaming responses for real-time output\n",
    "- Can be bound with tools for function calling\n",
    "\n",
    "**Common Chat Models:**\n",
    "- `ChatOllama` - Local models via Ollama\n",
    "- `ChatOpenAI` - OpenAI models (GPT-4, GPT-3.5)\n",
    "- `ChatAnthropic` - Claude models\n",
    "- `ChatOllama` - Ollama models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a8cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"granite4:tiny-h\", base_url=OLLAMA_BASE_URL)\n",
    "result = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6190cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb10b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330fabb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
