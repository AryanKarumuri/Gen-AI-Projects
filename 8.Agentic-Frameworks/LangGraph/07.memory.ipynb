{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e8e615",
   "metadata": {},
   "source": [
    "## Memory in Langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9568e981",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2a90bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OLLAMA_BASE_URL = os.getenv(\"OLLAMA_BASE_URL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e06fefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello! I'm doing well, thank you for asking. As an AI, I don't have feelings, but I'm functioning perfectly and ready to help you.\\n\\nHow are you doing today? Is there something specific I can help you with?\" additional_kwargs={} response_metadata={'model': 'glm-5:cloud', 'created_at': '2026-02-23T05:49:27.716999524Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6241148412, 'load_duration': None, 'prompt_eval_count': 11, 'prompt_eval_duration': None, 'eval_count': 491, 'eval_duration': None, 'logprobs': None, 'model_name': 'glm-5:cloud', 'model_provider': 'ollama'} id='lc_run--019c890b-8bfc-7191-bccb-e648328c492a-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 11, 'output_tokens': 491, 'total_tokens': 502}\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOllama(model=\"glm-5:cloud\", base_url=OLLAMA_BASE_URL)\n",
    "\n",
    "# checking the response\n",
    "result = llm.invoke(\"Hello!, how are you?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce82c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fada3e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from datetime import datetime\n",
    "\n",
    "@tool\n",
    "def date_time_tool() -> str:\n",
    "    \"\"\"Returns the current date and time.\"\"\"\n",
    "    return datetime.now().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af6a3267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "llm_with_tools = llm.bind_tools([date_time_tool])\n",
    "\n",
    "# Update the chatbot function to use llm_with_tools\n",
    "def chatbot(state: State):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "tool_node = ToolNode(tools=[date_time_tool])\n",
    "\n",
    "# Rebuild the graph with the new tools\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dd3f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d05250",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "`MemorySaver` is a checkpointer that stores the graph state in memory:\n",
    "\n",
    "- **`MemorySaver()`** - Creates an in-memory checkpointer to persist conversation state\n",
    "- **`checkpointer=memory`** - Passed to `compile()` to enable state persistence across invocations\n",
    "- Each conversation thread is identified by a `thread_id` in the config\n",
    "\n",
    "This allows the chatbot to remember previous messages in the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0fed58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bc989e",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "The `config` dictionary configures the conversation thread:\n",
    "\n",
    "- **`thread_id`** - A unique identifier for the conversation session\n",
    "- Different `thread_id` values create separate conversation histories\n",
    "- Same `thread_id` continues the existing conversation with memory\n",
    "\n",
    "**Example:**\n",
    "- `thread_id: \"1\"` → One conversation history\n",
    "- `thread_id: \"2\"` → A completely separate conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f51e4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hi there! How can I help you today?\n",
      "Assistant: \n",
      "Assistant: 2026-02-23T11:22:41.856339\n",
      "Assistant: Today's date is February 23, 2026. The current time is 11:22 AM.\n",
      "Assistant: I can help you with a wide variety of tasks! Here are some of the things I can do:\n",
      "\n",
      "**Writing & Communication**\n",
      "- Help write, edit, or proofread documents, emails, essays, and more\n",
      "- Assist with creative writing, stories, or poems\n",
      "- Help improve your writing style and clarity\n",
      "\n",
      "**Research & Information**\n",
      "- Answer questions on countless topics\n",
      "- Explain complex concepts in simple terms\n",
      "- Help you learn about new subjects\n",
      "\n",
      "**Problem Solving**\n",
      "- Help with math, coding, and logic problems\n",
      "- Brainstorm ideas and solutions\n",
      "- Break down complex problems into manageable steps\n",
      "\n",
      "**Productivity**\n",
      "- Help organize tasks and priorities\n",
      "- Create plans, outlines, and summaries\n",
      "- Assist with study guides and learning materials\n",
      "\n",
      "**Creative Projects**\n",
      "- Help with brainstorming and ideation\n",
      "- Provide feedback and suggestions\n",
      "- Assist with creative projects\n",
      "\n",
      "**Daily Tasks**\n",
      "- Provide the current date and time (as you saw earlier!)\n",
      "- Help with recipes, recommendations, and everyday questions\n",
      "- Assist with language translation and grammar\n",
      "\n",
      "What would you like help with today?\n",
      "Assistant: You've asked me the following questions in our conversation so far:\n",
      "\n",
      "1. **\"What is the date today?\"** - You asked for the current date, and I provided February 23, 2026.\n",
      "\n",
      "2. **\"What can you do for me?\"** - You asked about my capabilities, and I gave you an overview of the ways I can help.\n",
      "\n",
      "3. **\"What questions I have asked you so far?\"** - This current question asking me to recall your previous questions.\n",
      "\n",
      "That's three questions total! Is there anything else you'd like to know?\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Process user input through the LangGraph\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}, config):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff8e94",
   "metadata": {},
   "source": [
    "**Note on `MemorySaver`:**\n",
    "\n",
    "`MemorySaver` is an **in-memory** checkpointer, which means:\n",
    "\n",
    "- **Volatile Storage**: State is lost when the Python process restarts\n",
    "- **Best for**: Development, testing, and short-lived conversations\n",
    "- **Not for Production**: Use persistent checkpointers for production:\n",
    "  - `SqliteSaver` - SQLite database persistence\n",
    "  - `PostgresSaver` - PostgreSQL database persistence\n",
    "  - `RedisSaver` - Redis-based persistence\n",
    "\n",
    "**How Memory Works:**\n",
    "1. Each `graph.stream()` or `graph.invoke()` call with the same `thread_id` continues from the previous state\n",
    "2. The checkpointer saves the state after each node execution\n",
    "3. On the next invocation, the graph loads the previous state and appends new messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
